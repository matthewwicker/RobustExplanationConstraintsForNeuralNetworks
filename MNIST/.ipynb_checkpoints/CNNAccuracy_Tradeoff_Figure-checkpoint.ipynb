{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c581a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# *** I need to actually do something more sophisicated with normalization to ensure that these\n",
    "# inputs are normalized in the same waya as the ones we trained on, but Torch seems\n",
    "# a bit complicated to me on this front so I am ignoring it for now :) \n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "mnist_trainset = datasets.MNIST(root='./Datasets', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./Datasets', train=False, download=True, transform=None)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import XAIArchitectures\n",
    "import GradCertModule\n",
    "import pytorch_lightning as pl\n",
    "from pl_examples.basic_examples.mnist_datamodule import MNISTDataModule\n",
    "\n",
    "\n",
    "ALPHA = 0.00            # Regularization Parameter (Weights the Reg. Term)\n",
    "EPSILON = 0.00          # Input Peturbation Budget at Training Time\n",
    "GAMMA = 0.00             # Model Peturbation Budget at Training Time \n",
    "                        #(Changed to proportional budget rather than absolute)\n",
    "    \n",
    "LEARN_RATE = 0.001      # Learning Rate Hyperparameter\n",
    "HIDDEN_DIM = 100       # Hidden Neurons Hyperparameter\n",
    "HIDDEN_LAY = 1         # Hidden Layers Hyperparameter\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "EPSILON_LINEAR = True   # Put Epsilon on a Linear Schedule?\n",
    "GAMMA_LINEAR = True     # Put Gamma on a Linear Schedule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad244c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = XAIArchitectures.DeepMindSmall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a236a764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepMindSmall_e=0.0_g=0.0_a=0.1_s=True\n",
      "epoch\n",
      "global_step\n",
      "pytorch-lightning_version\n",
      "state_dict\n",
      "callbacks\n",
      "optimizer_states\n",
      "lr_schedulers\n",
      "hparams_name\n",
      "hyper_parameters\n"
     ]
    }
   ],
   "source": [
    "def load_model(model, gamma, epsilon):\n",
    "    SCHEDULED = EPSILON_LINEAR or GAMMA_LINEAR \n",
    "    ALPHA = 0.5\n",
    "    #DeepMindSmall_e=0.0_g=0.0_a=0.0_s=True.ckpt\n",
    "    MODEL_ID = \"DeepMindSmall_e=%s_g=%s_a=%s_s=%s\"%(epsilon, gamma, ALPHA, SCHEDULED)\n",
    "    print(MODEL_ID)\n",
    "    #MODEL_ID = \"DeepMindSmall_e=%s_g=%s_h=%s_l=%s_a=%s_s=%s\"%(EPSILON, GAMMA, HIDDEN_DIM, HIDDEN_LAY, ALPHA, SCHEDULED)   \n",
    "    ckpt = torch.load(\"GPU_Models/%s.ckpt\"%(MODEL_ID))\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    checkpoint = torch.load(\"GPU_Models/%s.ckpt\"%(MODEL_ID))\n",
    "    for key in checkpoint:\n",
    "        print(key)\n",
    "    model.load_state_dict(torch.load('GPU_Models/%s.pt'%(MODEL_ID)))\n",
    "\n",
    "    \n",
    "load_model(model, 0.0, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf190e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_acc(model):\n",
    "    acc = 0\n",
    "    for i in range(1000):\n",
    "        data = np.asarray(mnist_testset[i][0]).reshape(1,28,28)/255.0\n",
    "        target = torch.Tensor([mnist_testset[i][1]]).type(torch.LongTensor)\n",
    "        model(torch.Tensor(data[None, :]))\n",
    "        out = torch.argmax(model(torch.Tensor([data])))\n",
    "        if(target == out):\n",
    "            acc += 1\n",
    "    return acc/1000\n",
    "\n",
    "estimate_acc(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee37054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../GradCertModule.py:282: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/aten/src/ATen/native/TensorShape.cpp:2985.)\n",
      "  return dL_min.T, dL_max.T #dL_dz_min.T, dL_dz_max.T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10244.612017333984"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_gradcert(model):\n",
    "    val = 0\n",
    "    for i in range(1000):\n",
    "        data = np.asarray(mnist_testset[i][0]).reshape(1,28,28)/255.0\n",
    "        target = torch.Tensor([mnist_testset[i][1]]).type(torch.LongTensor)\n",
    "        data = torch.Tensor(data)\n",
    "        min_grad, max_grad = GradCertModule.GradCertBounds(model, data[None, :], target, 0.005, 0.00)\n",
    "        min_grad, max_grad = min_grad.detach().numpy(), max_grad.detach().numpy()\n",
    "        val += np.mean(max_grad - min_grad)\n",
    "    return val/1000\n",
    "\n",
    "estimate_gradcert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2211535",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_acc = 0.99\n",
    "zero_grad = 27.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c01703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepMindSmall_e=0.01_g=0.01_a=0.1_s=True\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GPU_Models/DeepMindSmall_e=0.01_g=0.01_a=0.1_s=True.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_16647/495853110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_16647/2714105254.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, gamma, epsilon)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#MODEL_ID = \"DeepMindSmall_e=%s_g=%s_h=%s_l=%s_a=%s_s=%s\"%(EPSILON, GAMMA, HIDDEN_DIM, HIDDEN_LAY, ALPHA, SCHEDULED)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPU_Models/%s.ckpt\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GPU_Models/DeepMindSmall_e=0.01_g=0.01_a=0.1_s=True.ckpt'"
     ]
    }
   ],
   "source": [
    "ALPHA = 0.5\n",
    "acc_grid = np.zeros((3,3))\n",
    "i = 0\n",
    "for e in [0.01, 0.025, 0.05]:\n",
    "    j = 0\n",
    "    for g in [0.01, 0.025, 0.05]:\n",
    "        load_model(model, e, g)\n",
    "        acc = estimate_acc(model)\n",
    "        print(acc)\n",
    "        acc_grid[i][j] = acc\n",
    "        j+=1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7170147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('poster')\n",
    "plt.figure(figsize=(10, 10), dpi=120)\n",
    "print(acc_grid)\n",
    "ax = sns.heatmap(acc_grid, annot=True, cmap=\"Blues\")\n",
    "ax.set_xticklabels([0.01, 0.025, 0.05])\n",
    "ax.set_yticklabels([0.01, 0.025, 0.05])\n",
    "ax.set_xlabel(r'$\\epsilon_t$')\n",
    "ax.set_ylabel(r'$\\gamma_t$')\n",
    "ax.set_title('Test Set Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.5\n",
    "val_grid = np.zeros((3,3))\n",
    "i = 0\n",
    "for e in [0.01, 0.025, 0.05]:\n",
    "    j = 0\n",
    "    for g in [0.01, 0.025, 0.05]:\n",
    "        load_model(model, e, g)\n",
    "        val = estimate_gradcert(model)\n",
    "        print(val)\n",
    "        val_grid[i][j] = val\n",
    "        j+=1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('poster')\n",
    "plt.figure(figsize=(10, 10), dpi=120)\n",
    "\n",
    "v_grid = val_grid #np.clip(val_grid, 0, 0.05)\n",
    "ax = sns.heatmap(v_grid, annot=True, cmap=\"Reds\")\n",
    "ax.set_xticklabels([0.01, 0.025, 0.05])\n",
    "ax.set_yticklabels([0.01, 0.025, 0.05])\n",
    "ax.set_xlabel(r'$\\epsilon_t$')\n",
    "ax.set_ylabel(r'$\\gamma_t$')\n",
    "ax.set_title('Avg. Bound Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['darkblue','darkred'])\n",
    "plt.figure(figsize=(6, 4), dpi=120)\n",
    "\n",
    "ax = sns.heatmap([[0.99, 27.56]], annot=True, cmap=cmap, fmt=\".2f\")\n",
    "\n",
    "ax.set_xticklabels([\"Acc.\", \"Bound Diff.\"])\n",
    "ax.set_yticklabels([\" \"])\n",
    "ax.set_xlabel(r' ')\n",
    "ax.set_ylabel(r' ')\n",
    "ax.set_title('Normally Trained NN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa07d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GradCertModule import run_mnist_attack\n",
    "from tqdm import trange\n",
    "def estimate_attack_robustness(model_to_test, epsilon=0.25):\n",
    "    ROBUST_COUNT = 0\n",
    "    INDEX = 0\n",
    "    for INDEX in trange(100):\n",
    "        x = np.asarray(mnist_testset[INDEX][0]).reshape(1,28,28)/255.0\n",
    "        x = torch.Tensor(x)\n",
    "        success = False\n",
    "        for targ in range(6):\n",
    "            success, x_adv, grad_adv = run_mnist_attack(model_to_test, x, target = targ, epsilon=epsilon, iterations=10, lr=epsilon/50)\n",
    "            if(success == True):\n",
    "                break\n",
    "        if(success == True):\n",
    "            #print(\"vulnerable\")\n",
    "            continue\n",
    "        else:\n",
    "            ROBUST_COUNT += 1\n",
    "            #print(\"Robust\")\n",
    "    return ROBUST_COUNT/100\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.5\n",
    "val_grid = np.zeros((5,5))\n",
    "i = 0\n",
    "for e in [0.01, 0.025, 0.05]:\n",
    "    j = 0\n",
    "    for g in [0.01, 0.025, 0.05, 0.1]:\n",
    "        load_model(model, e, g)\n",
    "        val = estimate_attack_robustness(model)\n",
    "        print(val)\n",
    "        val_grid[i][j] = val\n",
    "        j+=1\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
