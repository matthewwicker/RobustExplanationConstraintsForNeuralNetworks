{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becb5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pl_examples.basic_examples.mnist_datamodule import MNISTDataModule\n",
    "\n",
    "import GradCertModule\n",
    "\n",
    "ALPHA = 0.5            # Regularization Parameter (Weights the Reg. Term)\n",
    "EPSILON = 0.025          # Input Peturbation Budget at Training Time\n",
    "GAMMA = 0.00            # Model Peturbation Budget at Training Time \n",
    "                        #(Changed to proportional budget rather than absolute)\n",
    "    \n",
    "LEARN_RATE = 0.001     # Learning Rate Hyperparameter\n",
    "HIDDEN_DIM = 128       # Hidden Neurons Hyperparameter\n",
    "HIDDEN_LAY = 1         # Hidden Layers Hyperparameter\n",
    "MAX_EPOCHS = 5\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "EPSILON_LINEAR = True   # Put Epsilon on a Linear Schedule?\n",
    "GAMMA_LINEAR = True     # Put Gamma on a Linear Schedule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8837b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET MODE TO:  PGD\n"
     ]
    }
   ],
   "source": [
    "import XAIArchitectures\n",
    "model = XAIArchitectures.FullyConnected(mode='PGD')\n",
    "model.set_params(alpha=ALPHA, epsilon=EPSILON, gamma=GAMMA,\n",
    "                learn_rate=LEARN_RATE, max_epochs=MAX_EPOCHS,\n",
    "                epsilon_linear=EPSILON_LINEAR,gamma_linear=GAMMA_LINEAR,\n",
    "                mode=\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cf5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | lays | ModuleList | 101 K \n",
      "1 | l1   | Linear     | 100 K \n",
      "2 | lf   | Linear     | 1.3 K \n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3902030bf3fb4304bd6a2a4668c6cb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99861e9219d4e3ca9753c701b9a6cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9700000286102295\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "dm = MNISTDataModule(batch_size=BATCH_SIZE, num_workers=0)\n",
    "trainer = pl.Trainer(max_epochs=MAX_EPOCHS, accelerator=\"cpu\", devices=1)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "result = trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d6b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "ACC = round(result[0]['test_acc'],2)\n",
    "print(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f67712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "mnist_trainset = datasets.MNIST(root='./Datasets', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./Datasets', train=False, download=True, transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "07561f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "def init_dual_vars(model, inp, weights):\n",
    "    h = inp\n",
    "    duals = [torch.zeros_like(h, requires_grad=True)]\n",
    "    for i in range(len(model.layers)):\n",
    "        w = weights[2*(i)].double()\n",
    "        h = torch.matmul(h, w.T)\n",
    "        dual_i = torch.rand_like(h, requires_grad=True)\n",
    "        dual_i.requires_grad = True \n",
    "        duals.append(dual_i.float())\n",
    "    return duals\n",
    "\n",
    "weights = [t for t in model.parameters()]\n",
    "data = np.asarray(mnist_testset[0][0]).reshape(1, 28*28)/255.0\n",
    "inp = torch.tensor(data)\n",
    "\n",
    "duals = init_dual_vars(model, inp, weights)\n",
    "#duals_lam = init_dual_vars(model, inp, weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "093eccb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 1] doesn't match the broadcast shape [1, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_83547/1792929651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLegrangeForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_83547/1792929651.py\u001b[0m in \u001b[0;36mLegrangeForward\u001b[0;34m(model, weights, inp, duals, eps, gam)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mh_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Account for additional violation in activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mviolation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh_nom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mduals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mh_nom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_nom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mviolation\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mh_nom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mduals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 1] doesn't match the broadcast shape [1, 784]"
     ]
    }
   ],
   "source": [
    "def zeros_violation(W, b, x_l, x_u, dual_lam, dual_mus, i):\n",
    "    \n",
    "    return None\n",
    "\n",
    "def affine_legrange(W, b, x_l, x_u, dual_lam, dual_mus, i):\n",
    "    x_l = torch.maximum(x_l, x_l*0)\n",
    "    \n",
    "    x_mu = (x_u + x_l)/2\n",
    "    x_r = (x_u - x_l)/2\n",
    "    W_mu = W\n",
    "    h_mu = torch.matmul(x_mu, W_mu.T)\n",
    "    x_rad = torch.matmul(x_r, torch.abs(W_mu).T)\n",
    "    h_u = torch.maximum(h_mu + x_rad, h_mu*0)\n",
    "    h_l = torch.maximum(h_mu - x_rad, h_mu*0)\n",
    "    \n",
    "    \n",
    "    # Legrange Slack computations\n",
    "    elm_1 = torch.matmul(torch.maximum(duals[i] - torch.matmul(duals[i+1], W), 0.0*duals[i]).float(), x_u.T)\n",
    "    elm_2 = torch.matmul(torch.minimum(duals[i] - torch.matmul(duals[i+1], W), 0.0*duals[i]).float(), x_l.T)\n",
    "    elm_3 = torch.matmul(b, duals[i+1].T)\n",
    "    #print(elm_1, elm_2, elm_3)\n",
    "    violation = elm_1 + elm_2 + elm_3\n",
    "    \n",
    "    return h_u, h_l, violation\n",
    "\n",
    "\n",
    "def LegrangeForward(model, weights, inp, duals, eps, gam=0.0):\n",
    "    h_l = inp-eps; h_u = inp+eps\n",
    "    h_nom = inp.float()\n",
    "    assert((h_l <= h_u).all())\n",
    "    layers = int(len(weights)/2); \n",
    "    total_violation = 0\n",
    "    inter_upper = [h_u]\n",
    "    inter_lower = [h_l]\n",
    "    for i in range(len(model.layers)):\n",
    "        w, b = weights[2*(i)], weights[(2*(i))+1]\n",
    "        h_l, h_u, violation = affine_legrange(w, b, h_l, h_u, duals, i)\n",
    "        h_l = model.activations[0](h_l) \n",
    "        h_u = model.activations[0](h_u)\n",
    "        # Account for additional violation in activation\n",
    "        violation += h_nom * duals[i]\n",
    "        h_nom = torch.matmul(h_nom, w.T) + b\n",
    "        violation -= h_nom * duals[i+1]\n",
    "        inter_upper.append(h_u)\n",
    "        inter_lower.append(h_l)\n",
    "        total_violation += violation\n",
    "    return total_violation, inter_lower, inter_upper\n",
    "\n",
    "\n",
    "\n",
    "err, inter_l, inter_u = LegrangeForward(model, weights, inp.float(), duals, 0.001)\n",
    "print(err)\n",
    "for i in range(len(duals)):\n",
    "    duals[i].retain_grad()\n",
    "err.backward()\n",
    "\n",
    "\n",
    "for i in range(len(duals)):\n",
    "    duals[i] = duals[i] - (0.5 * duals[i].grad)\n",
    "    duals[i] = torch.maximum(0*duals[i] + 1e-5, duals[i])\n",
    "#    duals[i] = torch.clip(duals[i], inter_l[i], inter_u[i])\n",
    "#duals[0] = 0.0 * duals[0]\n",
    "#duals[-1] = 0.0 * duals[-1]\n",
    "err, l, u = LegrangeForward(model, weights, inp.float(), duals, 0.001)\n",
    "print(err)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0b802fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor([[1.0000e-05, 7.8633e-01, 3.7316e-01, 4.7445e-01, 1.0000e-05, 3.8070e-02,\n",
      "         8.7895e-01, 1.0000e-05, 2.0854e-01, 1.0000e-05, 9.1068e-01, 1.0000e-05,\n",
      "         7.2945e-01, 2.5741e-01, 1.0000e-05, 5.8614e-01, 1.0000e-05, 4.4511e-01,\n",
      "         3.2687e-01, 6.9129e-01, 7.9555e-01, 5.2564e-01, 4.5538e-01, 6.1062e-01,\n",
      "         9.1053e-01, 9.4523e-01, 8.5697e-02, 1.0000e-05, 5.4788e-01, 1.0000e-05,\n",
      "         1.0000e-05, 2.6331e-01, 1.0000e-05, 1.0000e-05, 5.4264e-01, 1.0000e-05,\n",
      "         9.2409e-01, 1.0000e-05, 3.8040e-01, 3.5321e-01, 1.0000e-05, 4.2646e-01,\n",
      "         5.7843e-02, 1.4960e-01, 5.4876e-01, 6.9140e-01, 6.2650e-01, 3.8110e-01,\n",
      "         1.0000e-05, 6.7312e-01, 1.0000e-05, 8.4383e-01, 3.4254e-01, 1.9977e-01,\n",
      "         1.0000e-05, 7.9841e-02, 1.0290e-01, 8.0575e-02, 1.9515e-01, 6.2817e-01,\n",
      "         1.0000e-05, 6.1023e-01, 4.1799e-01, 1.6566e-01, 5.0910e-01, 5.5896e-01,\n",
      "         1.0000e-05, 6.2614e-01, 3.3937e-01, 1.0000e-05, 9.6820e-01, 4.6807e-01,\n",
      "         8.3877e-01, 1.0000e-05, 6.4230e-01, 1.0000e-05, 1.6789e-01, 1.0000e-05,\n",
      "         9.6370e-01, 9.1457e-01, 6.4068e-01, 1.0000e-05, 5.8673e-01, 7.6603e-01,\n",
      "         6.2261e-01, 4.1904e-01, 1.4726e-01, 1.0000e-05, 1.0000e-05, 2.9903e-01,\n",
      "         1.0000e-05, 2.3522e-01, 8.7793e-01, 6.7618e-01, 1.0000e-05, 1.0000e-05,\n",
      "         1.0000e-05, 1.0000e-05, 7.0418e-01, 9.7485e-01, 2.1690e-01, 2.3935e-01,\n",
      "         1.4638e-01, 5.4393e-01, 1.9977e-01, 1.0000e-05, 1.0000e-05, 6.9187e-01,\n",
      "         1.0000e-05, 1.9429e-01, 2.5174e-01, 5.6220e-01, 1.0000e-05, 1.0000e-05,\n",
      "         1.0000e-05, 8.5425e-01, 3.7047e-01, 1.0000e-05, 4.8576e-01, 1.0000e-05,\n",
      "         2.3806e-01, 2.7253e-01, 1.0546e+00, 7.9263e-01, 7.4377e-01, 8.9887e-01,\n",
      "         6.5817e-01, 7.3294e-01]], grad_fn=<MaximumBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in duals:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
