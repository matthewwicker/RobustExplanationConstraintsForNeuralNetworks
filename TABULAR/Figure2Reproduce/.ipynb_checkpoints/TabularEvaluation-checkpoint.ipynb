{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11324e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Imports\n",
    "from typing import Union\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "import data_utils\n",
    "import GradCertModule\n",
    "import XAIArchitectures\n",
    "# Deep Learning Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pytorch_lightning as pl\n",
    "# Standard Lib Imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 0\n",
    "import numpy as np\n",
    "import random\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "dataset = \"GERMAN\"\n",
    "\n",
    "if(dataset == \"GERMAN\"):\n",
    "    negative_cls = 0\n",
    "    sensitive_features = [] \n",
    "    sens = ['status_sex_A91', 'status_sex_A92', 'status_sex_A93', 'status_sex_A94']\n",
    "    drop_columns = []\n",
    "    train_ds, test_ds = data_utils.get_german_data(sensitive_features, drop_columns=drop_columns)\n",
    "\n",
    "elif(dataset == \"CREDIT\"):\n",
    "    negative_cls = 1\n",
    "    sensitive_features = [] \n",
    "    sens = ['x2_1.0', 'x2_2.0']\n",
    "    drop_columns = []\n",
    "    train_ds, test_ds = data_utils.get_credit_data(sensitive_features, drop_columns=drop_columns)\n",
    "    \n",
    "elif(dataset == \"ADULT\"):\n",
    "    negative_cls = 1\n",
    "    sensitive_features = [] \n",
    "    sens = ['sex_Female', 'sex_Male', 'race_Amer-Indian-Eskimo', \n",
    "            'race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White',]\n",
    "    drop_columns = ['native-country'] #, 'education']\n",
    "    train_ds, test_ds = data_utils.get_adult_data(sensitive_features, drop_columns=drop_columns)\n",
    "    \n",
    "elif(dataset == \"CRIME\"):\n",
    "    negative_cls = 1\n",
    "    CRIME_DROP_COLUMNS = [\n",
    "    'HispPerCap', 'LandArea', 'LemasPctOfficDrugUn', 'MalePctNevMarr',\n",
    "    'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'MedRent',\n",
    "    'MedYrHousBuilt', 'OwnOccHiQuart', 'OwnOccLowQuart',\n",
    "    'OwnOccMedVal', 'PctBornSameState', 'PctEmplManu',\n",
    "    'PctEmplProfServ', 'PctEmploy', 'PctForeignBorn', 'PctImmigRec5',\n",
    "    'PctImmigRec8', 'PctImmigRecent', 'PctRecImmig10', 'PctRecImmig5',\n",
    "    'PctRecImmig8', 'PctRecentImmig', 'PctSameCity85',\n",
    "    'PctSameState85', 'PctSpeakEnglOnly', 'PctUsePubTrans',\n",
    "    'PctVacMore6Mos', 'PctWorkMom', 'PctWorkMomYoungKids',\n",
    "    'PersPerFam', 'PersPerOccupHous', 'PersPerOwnOccHous',\n",
    "    'PersPerRentOccHous', 'RentHighQ', 'RentLowQ', 'Unnamed: 0',\n",
    "    'agePct12t21', 'agePct65up', 'householdsize', 'indianPerCap',\n",
    "    'pctUrban', 'pctWFarmSelf', 'pctWRetire', 'pctWSocSec', 'pctWWage',\n",
    "    'whitePerCap'\n",
    "    ]\n",
    "    sensitive_features = []\n",
    "    sens = ['racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp']\n",
    "    train_ds, test_ds = data_utils.get_crime_data(sensitive_features, drop_columns=CRIME_DROP_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a03dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'age', 'credit_amount', 'credits_num', 'dependants_num', 'duration', 'installment_rate_pct', 'residence_since', 'account_status_A11', 'account_status_A12', 'account_status_A13', 'account_status_A14', 'credit_history_A30', 'credit_history_A31', 'credit_history_A32', 'credit_history_A33', 'credit_history_A34', 'debtors_guarantors_A101', 'debtors_guarantors_A102', 'debtors_guarantors_A103', 'employment_A71', 'employment_A72', 'employment_A73', 'employment_A74', 'employment_A75', 'foreign_A201', 'foreign_A202', 'housing_A151', 'housing_A152', 'housing_A153', 'job_A171', 'job_A172', 'job_A173', 'job_A174', 'other_installment_plans_A141', 'other_installment_plans_A142', 'other_installment_plans_A143', 'property_A121', 'property_A122', 'property_A123', 'property_A124', 'purpose_A40', 'purpose_A41', 'purpose_A410', 'purpose_A42', 'purpose_A43', 'purpose_A44', 'purpose_A45', 'purpose_A46', 'purpose_A48', 'purpose_A49', 'savings_account_A61', 'savings_account_A62', 'savings_account_A63', 'savings_account_A64', 'savings_account_A65', 'status_sex_A91', 'status_sex_A92', 'status_sex_A93', 'status_sex_A94', 'telephone_A191', 'telephone_A192']\n"
     ]
    }
   ],
   "source": [
    "#print(train_ds.X_df.columns.tolist())\n",
    "cols = train_ds.X_df.columns.tolist()\n",
    "print(cols)\n",
    "sens_inds = []\n",
    "#sens += ['age', 'dependants_num']\n",
    "for i in sens:\n",
    "    sens_inds.append(cols.index(i))\n",
    "#print(sens_inds)\n",
    "\n",
    "if(dataset == \"ADULT\"):\n",
    "    AGE = [cols.index('age')]\n",
    "    RACE = [cols.index(i) for i in ['race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White']]\n",
    "    GENDER = [cols.index(i) for i in ['sex_Female', 'sex_Male']]\n",
    "    FINANCES = [cols.index(i) for i in ['capital-gain', 'capital-loss']]\n",
    "    EDUCATION = [cols.index(i) for i in ['education_10th', 'education_11th', 'education_12th', 'education_1st-4th', 'education_5th-6th', 'education_7th-8th', 'education_9th', \n",
    "                                         'education_Assoc-acdm', 'education_Assoc-voc', 'education_Bachelors', 'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
    "                                         'education_Preschool', 'education_Prof-school', 'education_Some-college']]     \n",
    "    EMPLOYMENT = [cols.index(i) for i in ['hours-per-week', 'occupation_Adm-clerical', 'occupation_Armed-Forces', 'occupation_Craft-repair', 'occupation_Exec-managerial', 'occupation_Farming-fishing', \n",
    "                                          'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct', 'occupation_Other-service', 'occupation_Priv-house-serv', 'occupation_Prof-specialty', \n",
    "                                          'occupation_Protective-serv', 'occupation_Sales', 'occupation_Tech-support', 'occupation_Transport-moving', 'workclass_Local-gov', 'workclass_Private',\n",
    "                                          'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc', 'workclass_State-gov', 'workclass_Without-pay']]          \n",
    "    PERSONAL = [cols.index(i) for i in ['hours-per-week', 'relationship_Husband', 'relationship_Not-in-family', 'relationship_Other-relative', 'relationship_Own-child', 'relationship_Unmarried', 'relationship_Wife', 'marital-status_Divorced',\n",
    "                                        'marital-status_Married-AF-spouse', 'marital-status_Married-civ-spouse', 'marital-status_Married-spouse-absent', 'marital-status_Never-married', 'marital-status_Separated', 'marital-status_Widowed']]\n",
    "                           \n",
    "elif(dataset == \"CREDIT\"):\n",
    "    AMOUNT = [cols.index('x1')]\n",
    "    AGE = [cols.index(i) for i in [ 'x5_21.0', 'x5_22.0', 'x5_23.0', 'x5_24.0', 'x5_25.0', 'x5_26.0', 'x5_27.0', 'x5_28.0', 'x5_29.0', 'x5_30.0', 'x5_31.0', \n",
    "                                   'x5_32.0', 'x5_33.0', 'x5_34.0', 'x5_35.0', 'x5_36.0', 'x5_37.0', 'x5_38.0', 'x5_39.0', 'x5_40.0', 'x5_41.0', 'x5_42.0', \n",
    "                                   'x5_43.0', 'x5_44.0', 'x5_45.0', 'x5_46.0', 'x5_47.0', 'x5_48.0', 'x5_49.0', 'x5_50.0', 'x5_51.0', 'x5_52.0', 'x5_53.0', \n",
    "                                   'x5_54.0', 'x5_55.0', 'x5_56.0', 'x5_57.0', 'x5_58.0', 'x5_59.0', 'x5_60.0', 'x5_61.0', 'x5_62.0', 'x5_63.0', 'x5_64.0', \n",
    "                                   'x5_65.0', 'x5_66.0', 'x5_67.0', 'x5_68.0', 'x5_69.0', 'x5_70.0', 'x5_71.0', 'x5_72.0', 'x5_73.0', 'x5_74.0', 'x5_75.0', \n",
    "                                   'x5_79.0']]\n",
    "    GENDER = [cols.index(i) for i in ['x2_1.0', 'x2_2.0']]\n",
    "    EDUCATION = [cols.index(i) for i in ['x2_1.0', 'x2_2.0']]\n",
    "    PERSONAL = [cols.index(i) for i in ['x4_0.0', 'x4_1.0', 'x4_2.0', 'x4_3.0']]\n",
    "    BILLS = [cols.index(i) for i in ['x12', 'x13', 'x14', 'x15', 'x16', 'x17']]\n",
    "    PAYMENTS = [cols.index(i) for i in ['x6_-1.0', 'x6_-2.0', 'x6_0.0', 'x6_1.0', 'x6_2.0', 'x6_3.0', 'x6_4.0', 'x6_5.0', 'x6_6.0', 'x6_7.0', 'x6_8.0', \n",
    "                                        'x7_-1.0', 'x7_-2.0', 'x7_0.0', 'x7_1.0', 'x7_2.0', 'x7_3.0', 'x7_4.0', 'x7_5.0', 'x7_6.0', 'x7_7.0', 'x7_8.0', \n",
    "                                        'x8_-1.0', 'x8_-2.0', 'x8_0.0', 'x8_1.0', 'x8_2.0', 'x8_3.0', 'x8_4.0', 'x8_5.0', 'x8_6.0', 'x8_7.0', 'x8_8.0', \n",
    "                                        'x9_-1.0', 'x9_-2.0', 'x9_0.0', 'x9_1.0', 'x9_2.0', 'x9_3.0', 'x9_4.0', 'x9_5.0', 'x9_6.0', 'x9_7.0', 'x9_8.0', \n",
    "                                        'x10_-1.0', 'x10_-2.0', 'x10_0.0', 'x10_2.0', 'x10_3.0', 'x10_4.0', 'x10_5.0', 'x10_6.0', 'x10_7.0', 'x10_8.0', \n",
    "                                        'x11_-1.0', 'x11_-2.0', 'x11_0.0', 'x11_2.0', 'x11_3.0', 'x11_4.0', 'x11_5.0', 'x11_6.0', 'x11_7.0', 'x11_8.0',\n",
    "                                        'x18', 'x19', 'x20', 'x21', 'x22', 'x23']]\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f48a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_ds.X_df.to_numpy()\n",
    "y_train = torch.squeeze(torch.Tensor(train_ds.y_df.to_numpy()).to(torch.int64))\n",
    "\n",
    "X_test = test_ds.X_df.to_numpy()\n",
    "y_test = torch.squeeze(torch.Tensor(test_ds.y_df.to_numpy()).to(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1d88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class custDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X).float()\n",
    "        self.y = y\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "\n",
    "CustTrain = custDataset(X_train, y_train)    \n",
    "CustTest = custDataset(X_test, y_test)\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train, val, test, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_data = train\n",
    "        self.val_data = val\n",
    "        self.test_data = test\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "    \n",
    "dm = CustomDataModule(CustTrain, CustTest, CustTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f3c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1.0            # Regularization Parameter (Weights the Reg. Term)\n",
    "EPSILON = 0.0          # Input Peturbation Budget at Training Time\n",
    "GAMMA = 0.0            # Model Peturbation Budget at Training Time \n",
    "                       #(Changed to proportional budget rather than absolute)\n",
    "    \n",
    "LEARN_RATE = 0.0005     # Learning Rate Hyperparameter\n",
    "HIDDEN_DIM = 256       # Hidden Neurons Hyperparameter\n",
    "HIDDEN_LAY = 2         # Hidden Layers Hyperparameter\n",
    "MAX_EPOCHS = 25\n",
    "\n",
    "EPSILON_LINEAR = True   # Put Epsilon on a Linear Schedule?\n",
    "GAMMA_LINEAR = True     # Put Gamma on a Linear Schedule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca09bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET MODE TO:  GRAD\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = XAIArchitectures.FullyConnected(hidden_dim=HIDDEN_DIM, hidden_lay=HIDDEN_LAY, dataset=dataset)\n",
    "model.set_params(alpha=ALPHA, epsilon=EPSILON, gamma=GAMMA, \n",
    "                learn_rate=LEARN_RATE, max_epochs=MAX_EPOCHS,\n",
    "                epsilon_linear=EPSILON_LINEAR, gamma_linear=GAMMA_LINEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15072302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "global_step\n",
      "pytorch-lightning_version\n",
      "state_dict\n",
      "loops\n",
      "callbacks\n",
      "optimizer_states\n",
      "lr_schedulers\n",
      "hparams_name\n",
      "hyper_parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SCHEDULED = EPSILON_LINEAR or GAMMA_LINEAR    \n",
    "#MODEL_ID = \"FCN_e=%s_g=%s_h=%s_l=%s_s=%s\"%(EPSILON, GAMMA, HIDDEN_DIM, HIDDEN_LAY, SCHEDULED)  \n",
    "MODEL_ID = \"%s_FCN_e=%s_g=%s_a=%s_l=%s_h=%s_s=%s\"%(dataset, EPSILON, GAMMA, ALPHA, HIDDEN_LAY, HIDDEN_DIM, SCHEDULED)\n",
    "ckpt = torch.load(\"Models/%s.ckpt\"%(MODEL_ID))\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "checkpoint = torch.load(\"Models/%s.ckpt\"%(MODEL_ID))\n",
    "for key in checkpoint:\n",
    "    print(key)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c964cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure Test Set Accuracy\n",
    "def get_test_acc(MODEL_ID):\n",
    "    correct = 0\n",
    "    for INDEX in range(len(X_test)):\n",
    "        data = torch.Tensor([X_test[INDEX]])\n",
    "        out, cls = model.classify(data)\n",
    "        if(cls == y_test[INDEX]):\n",
    "            correct += 1 \n",
    "    correct /= len(X_test)\n",
    "    #print(\"Test set accuracy: \", correct)\n",
    "    return correct\n",
    "get_test_acc(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5689b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:00<00:03,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357174038887024\n",
      "[42, 26, 1, 49] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:00<00:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.9613151550293\n",
      "[2, 48, 12, 5] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 3/10 [00:01<00:02,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057210903614759445\n",
      "[41, 5, 48, 3] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [00:01<00:02,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1347856521606445\n",
      "[2, 5, 12, 35] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [00:02<00:02,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.795168354525912e-14\n",
      "[42, 26, 49, 1] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [00:02<00:01,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001161572989076376\n",
      "[26, 42, 54, 49] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [00:02<00:01,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.448511836674385e-10\n",
      "[42, 26, 49, 1] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [00:03<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.912625162338372e-06\n",
      "[5, 12, 2, 35] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:03<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.484565250885041e-18\n",
      "[42, 26, 1, 49] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.971414863634948e-10\n",
      "[42, 49, 26, 30] [56, 57, 58, 59, 1, 1, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure Input Attack Robustness\n",
    "from tqdm import trange\n",
    "def get_input_attk(MODEL_ID, EPS=0.5, N=1):\n",
    "    model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n",
    "    model.inputfooling_OFF()\n",
    "    fooled = 0\n",
    "    for INDEX in trange(N):\n",
    "        success, x_adv, grad_adv = GradCertModule.run_tabular_attack(model, torch.Tensor(X_test[INDEX]), iterations=100,\n",
    "                                                      target=sens_inds, epsilon=EPS, lr=0.01, idx = 4)\n",
    "        fooled += int(success)\n",
    "    model.inputfooling_OFF()\n",
    "    return fooled/N\n",
    "    #print(\"Input Attack Fooling Rate: \", fooled/5)\n",
    "    \n",
    "get_input_attk(MODEL_ID, N=10, EPS=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfac1b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'safd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_24765/3083834469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'safd' is not defined"
     ]
    }
   ],
   "source": [
    "asf = safd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfdfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure Model Attack Robustness\n",
    "def get_model_attk(MODEL_ID, GAM=0.5, N=10):\n",
    "    model.inputfooling_ON()\n",
    "    fooled = 0\n",
    "    for INDEX in trange(N):\n",
    "        model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n",
    "        model.inputfooling_ON()\n",
    "        success, grad_orig, grad_adv = GradCertModule.run_tabular_model_attack_FGSM(model, torch.Tensor(X_test[INDEX]), iterations=50,\n",
    "                                                      target=sens_inds, gamma=GAM, lr=0.01*GAM, idx=10) #min(GAM/25, 0.01))\n",
    "        \n",
    "        \n",
    "        #print(grad_orig)\n",
    "        #print(grad_adv)\n",
    "        fooled += int(success)\n",
    "        #model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n",
    "        #model.inputfooling_ON()\n",
    "        #print(fooled)\n",
    "    model.inputfooling_OFF()  \n",
    "    return fooled/N\n",
    "    #print(\"Model Attack Fooling Rate: \", fooled/5)\n",
    "\n",
    "print(get_model_attk(MODEL_ID, GAM=0.05, N=10))    \n",
    "    \n",
    "#print(get_model_attk(MODEL_ID, GAM=0.1, N=10))\n",
    "\n",
    "#print(get_model_attk(MODEL_ID, GAM=0.2, N=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fddded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asdf = asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure Input Attack Certification\n",
    "def get_input_cert(MODEL_ID, EPS=0.2):\n",
    "    model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n",
    "    import copy\n",
    "    certified = 0\n",
    "    for INDEX in trange(200):\n",
    "        lower, upper = GradCertModule.GradCertBounds(model, torch.Tensor(X_test[INDEX][None, :]),\n",
    "                                                     y_test[INDEX], eps=EPS, gam=0.00, nclasses=2)\n",
    "\n",
    "        upper = np.squeeze(upper.detach().numpy())\n",
    "        lower = np.squeeze(lower.detach().numpy())\n",
    "        #print(upper[sens_inds])\n",
    "        #print(lower[sens_inds])\n",
    "        temp = copy.deepcopy(lower)\n",
    "        for i in sens_inds:\n",
    "            temp[i] = upper[i]\n",
    "        #print(temp[sens_inds])\n",
    "        top_idx = np.squeeze(np.argsort(temp))\n",
    "        top_idx = list(reversed(top_idx))\n",
    "        #print(set(top_idx[0:10]))\n",
    "        #print( set(sens_inds))\n",
    "        cert = not bool(set(top_idx[0:5]) & set(sens_inds))\n",
    "        certified += int(cert)\n",
    "        #break\n",
    "    #print(\"Input Attack Certified: \", certified/200)\n",
    "    return certified/200\n",
    "\n",
    "get_input_cert(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757706a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure Input Attack Certification\n",
    "def get_model_cert(MODEL_ID, GAM=0.2):\n",
    "    model.load_state_dict(torch.load('Models/%s.pt'%(MODEL_ID)))\n",
    "    import copy\n",
    "    certified = 0\n",
    "    for INDEX in trange(200):\n",
    "        lower, upper = GradCertModule.GradCertBounds(model, torch.Tensor(X_test[INDEX][None, :]),\n",
    "                                                     y_test[INDEX], eps=0.00, gam=GAM, nclasses=2)\n",
    "\n",
    "        upper = np.squeeze(upper.detach().numpy())\n",
    "        lower = np.squeeze(lower.detach().numpy())\n",
    "        #print(upper[sens_inds])\n",
    "        #print(lower[sens_inds])\n",
    "        temp = copy.deepcopy(lower)\n",
    "        for i in sens_inds:\n",
    "            temp[i] = upper[i]\n",
    "        #print(temp[sens_inds])\n",
    "        top_idx = np.squeeze(np.argsort(temp))\n",
    "        top_idx = list(reversed(top_idx))\n",
    "        #print(set(top_idx[0:10]))\n",
    "        #print( set(sens_inds))\n",
    "        cert = not bool(set(top_idx[0:5]) & set(sens_inds))\n",
    "        certified += int(cert)\n",
    "        #break\n",
    "    return certified/200\n",
    "    #print(\"Model Attack Certified: \", certified/200)\n",
    "get_model_cert(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_id(GAM_T=0.0, EPS_T=0.0):\n",
    "\n",
    "    ALPHA = 1.0            # Regularization Parameter (Weights the Reg. Term)\n",
    "    EPSILON = EPS_T         # Input Peturbation Budget at Training Time\n",
    "\n",
    "    LEARN_RATE = 0.0005     # Learning Rate Hyperparameter\n",
    "    HIDDEN_DIM = 256       # Hidden Neurons Hyperparameter\n",
    "    HIDDEN_LAY = 2         # Hidden Layers Hyperparameter\n",
    "    MAX_EPOCHS = 25\n",
    "\n",
    "    EPSILON_LINEAR = True   # Put Epsilon on a Linear Schedule?\n",
    "    GAMMA_LINEAR = True     # Put Gamma on a Linear Schedule?\n",
    "    \n",
    "    MODEL_ID = \"%s_FCN_e=%s_g=%s_a=%s_l=%s_h=%s_s=%s\"%(dataset, EPSILON, GAM_T, ALPHA, HIDDEN_LAY, HIDDEN_DIM, SCHEDULED)     \n",
    "    print(MODEL_ID)\n",
    "    return MODEL_ID\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark each baseline along with our method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CERT_VALS = []\n",
    "eps_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "for eps in eps_vals:\n",
    "    M_ID = gen_model_id(EPS_T=eps)\n",
    "    val = []\n",
    "    for e_test in np.linspace(0, 0.2, 20): #[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]:\n",
    "        certified = get_input_cert(M_ID, EPS=e_test)\n",
    "        val.append(certified)\n",
    "    #print(\"*****\")\n",
    "    #print(gam, val)\n",
    "    #print(\"*****\")\n",
    "    CERT_VALS.append(val)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "sns.set_context('poster')\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "\n",
    "\n",
    "eps_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "g_test = [0.0, 0.01, 0.02, 0.03, 0.05, 0.06]\n",
    "\n",
    "pal = sns.cubehelix_palette(n_colors=len(gamma_vals), start=.5, rot=-.75)\n",
    "print(pal.as_hex())\n",
    "\n",
    "for i in range(len(eps_vals)):\n",
    "    print(CERT_VALS[i])\n",
    "    plt.plot(CERT_VALS[i], label=gamma_vals[i], \n",
    "             color=pal[i], linewidth=10)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([0,4,9,14,19])\n",
    "labs = [round(i, 2) for i in np.linspace(0, 0.2, 5)]\n",
    "ax.set_xticklabels(labs)\n",
    "#ax.set_xticklabels(g_test)\n",
    "plt.title(\"%s\"%(dataset))\n",
    "plt.ylabel(\"Input Certified Robustness\")\n",
    "plt.xlabel(r\"Magnitude of $\\epsilon$\")\n",
    "ax.get_legend().set_title(r\"$\\epsilon_t$\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CERT_VALS = []\n",
    "gam_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "for gam in gam_vals:\n",
    "    M_ID = gen_model_id(gam)\n",
    "    val = []\n",
    "    for g_test in np.linspace(0, 0.2, 20): #[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]:\n",
    "        certified = get_model_cert(M_ID, GAM=g_test)\n",
    "        val.append(certified)\n",
    "    print(\"*****\")\n",
    "    print(gam, val)\n",
    "    print(\"*****\")\n",
    "    CERT_VALS.append(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29091e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "sns.set_context('poster')\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "\n",
    "\n",
    "gamma_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "g_test = [0.0, 0.01, 0.02, 0.03, 0.05, 0.06]\n",
    "\n",
    "pal = sns.cubehelix_palette(n_colors=len(gamma_vals), start=.5, rot=-.75)\n",
    "print(pal.as_hex())\n",
    "\n",
    "for i in range(len(gam_vals)):\n",
    "    print(CERT_VALS[i])\n",
    "    plt.plot(CERT_VALS[i], label=gamma_vals[i], \n",
    "             color=pal[i], linewidth=10)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([0,4,9,14,19])\n",
    "labs = [round(i, 2) for i in np.linspace(0, 0.2, 5)]\n",
    "ax.set_xticklabels(labs)\n",
    "#ax.set_xticklabels(g_test)\n",
    "plt.title(\"%s\"%(dataset))\n",
    "plt.ylabel(\"Model Certified Robustness\")\n",
    "plt.xlabel(r\"Magnitude of $\\gamma$\")\n",
    "ax.get_legend().set_title(r\"$\\gamma_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734008b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATTK_VALS = []\n",
    "gam_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "for gam in gam_vals:\n",
    "    M_ID = gen_model_id(gam)\n",
    "    val = []\n",
    "    for g_test in [0.01, 0.05, 0.075, 0.1, 0.125, 0.175]:\n",
    "        certified = get_model_attk(M_ID, GAM=g_test, N=50)\n",
    "        print(certified)\n",
    "        val.append(certified)\n",
    "    print(\"*****\")\n",
    "    print(gam, val)\n",
    "    print(\"*****\")\n",
    "    ATTK_VALS.append(val)\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ATTK_VALS = [[0.0, 0.04, 0.04, 0.1, 0.18, 0.66], \n",
    "            [0.02, 0.08, 0.02, 0.04, 0.0, 0.0], \n",
    "            [0.02, 0.02, 0.0, 0.02, 0.0, 0.0], \n",
    "            [0.04, 0.04, 0.02, 0.02, 0.0, 0.02], \n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "            [0.0, 0.0, 0.08, 0.34, 0.4, 0.6]]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "sns.set_context('poster')\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "\n",
    "\n",
    "gam_vals = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "g_test_vals = [0.01, 0.05, 0.075, 0.1, 0.125, 0.25]\n",
    "    \n",
    "    \n",
    "pal = sns.cubehelix_palette()\n",
    "pal = pal.as_hex()\n",
    "pal = [i for i in reversed(pal)]\n",
    "print(pal)\n",
    "#print(pal.as_hex())\n",
    "\n",
    "for i in range(len(gam_vals)):\n",
    "    plt.plot(1-np.asarray(ATTK_VALS[i]), label=gam_vals[i], color=pal[i], linewidth=10)\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xticks(range(len(g_test_vals)))\n",
    "ax.set_xticklabels(g_test_vals)\n",
    "\n",
    "plt.title(\"%s\"%(dataset))\n",
    "plt.ylabel(\"Model Attack Robustness\")\n",
    "plt.xlabel(r\"Magnitude of $\\gamma$\")\n",
    "ax.get_legend().set_title(r\"$\\gamma_t$\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
