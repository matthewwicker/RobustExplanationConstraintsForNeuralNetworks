{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c526ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/Desktop/Development/CertifiedExplanations/TABULAR/data_utils.py:251: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[cf] = features[cf].astype(str).astype('category')\n"
     ]
    }
   ],
   "source": [
    "# Custom Imports\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import data_utils\n",
    "import GradCertModule\n",
    "import XAIArchitectures\n",
    "# Deep Learning Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import pytorch_lightning as pl\n",
    "# Standard Lib Imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = \"CREDIT\"\n",
    "\n",
    "if(dataset == \"GERMAN\"):\n",
    "    negative_cls = 0\n",
    "    sensitive_features = [] #['status_sex']\n",
    "    drop_columns = []\n",
    "    minority_indicators = ['status_sex_A92']\n",
    "    train_ds, test_ds = data_utils.get_german_data(sensitive_features, drop_columns=drop_columns)\n",
    "\n",
    "elif(dataset == \"CREDIT\"):\n",
    "    negative_cls = 1\n",
    "    sensitive_features = [] #['x2']\n",
    "    drop_columns = []\n",
    "    minority_indicators = ['x2_2.0'] # Gender, Female\n",
    "    train_ds, test_ds = data_utils.get_credit_data(sensitive_features, drop_columns=drop_columns)\n",
    "    \n",
    "elif(dataset == \"ADULT\"):\n",
    "    sensitive_features = []\n",
    "    drop_columns = ['native-country'] #, 'education']\n",
    "    minority_indicators = ['sex_Female']\n",
    "    train_ds, test_ds = data_utils.get_adult_data(sensitive_features, drop_columns=drop_columns)\n",
    "    \n",
    "elif(dataset == \"CRIME\"):\n",
    "    negative_cls = 1\n",
    "    CRIME_DROP_COLUMNS = [\n",
    "    'HispPerCap', 'LandArea', 'LemasPctOfficDrugUn', 'MalePctNevMarr',\n",
    "    'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'MedRent',\n",
    "    'MedYrHousBuilt', 'OwnOccHiQuart', 'OwnOccLowQuart',\n",
    "    'OwnOccMedVal', 'PctBornSameState', 'PctEmplManu',\n",
    "    'PctEmplProfServ', 'PctEmploy', 'PctForeignBorn', 'PctImmigRec5',\n",
    "    'PctImmigRec8', 'PctImmigRecent', 'PctRecImmig10', 'PctRecImmig5',\n",
    "    'PctRecImmig8', 'PctRecentImmig', 'PctSameCity85',\n",
    "    'PctSameState85', 'PctSpeakEnglOnly', 'PctUsePubTrans',\n",
    "    'PctVacMore6Mos', 'PctWorkMom', 'PctWorkMomYoungKids',\n",
    "    'PersPerFam', 'PersPerOccupHous', 'PersPerOwnOccHous',\n",
    "    'PersPerRentOccHous', 'RentHighQ', 'RentLowQ', 'Unnamed: 0',\n",
    "    'agePct12t21', 'agePct65up', 'householdsize', 'indianPerCap',\n",
    "    'pctUrban', 'pctWFarmSelf', 'pctWRetire', 'pctWSocSec', 'pctWWage',\n",
    "    'whitePerCap'\n",
    "    ]\n",
    "    sensitive_features = []# ['racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp']\n",
    "    train_ds, test_ds = data_utils.get_crime_data(sensitive_features, drop_columns=CRIME_DROP_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1863a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_ds.X_df.to_numpy()\n",
    "y_train = torch.squeeze(torch.Tensor(train_ds.y_df.to_numpy()).to(torch.int64))\n",
    "\n",
    "X_test = test_ds.X_df.to_numpy()\n",
    "y_test = torch.squeeze(torch.Tensor(test_ds.y_df.to_numpy()).to(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c70f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x10_-1.0', 'x10_-2.0', 'x10_0.0', 'x10_2.0', 'x10_3.0', 'x10_4.0', 'x10_5.0', 'x10_6.0', 'x10_7.0', 'x10_8.0', 'x11_-1.0', 'x11_-2.0', 'x11_0.0', 'x11_2.0', 'x11_3.0', 'x11_4.0', 'x11_5.0', 'x11_6.0', 'x11_7.0', 'x11_8.0', 'x2_1.0', 'x2_2.0', 'x3_0.0', 'x3_1.0', 'x3_2.0', 'x3_3.0', 'x3_4.0', 'x3_5.0', 'x3_6.0', 'x4_0.0', 'x4_1.0', 'x4_2.0', 'x4_3.0', 'x5_21.0', 'x5_22.0', 'x5_23.0', 'x5_24.0', 'x5_25.0', 'x5_26.0', 'x5_27.0', 'x5_28.0', 'x5_29.0', 'x5_30.0', 'x5_31.0', 'x5_32.0', 'x5_33.0', 'x5_34.0', 'x5_35.0', 'x5_36.0', 'x5_37.0', 'x5_38.0', 'x5_39.0', 'x5_40.0', 'x5_41.0', 'x5_42.0', 'x5_43.0', 'x5_44.0', 'x5_45.0', 'x5_46.0', 'x5_47.0', 'x5_48.0', 'x5_49.0', 'x5_50.0', 'x5_51.0', 'x5_52.0', 'x5_53.0', 'x5_54.0', 'x5_55.0', 'x5_56.0', 'x5_57.0', 'x5_58.0', 'x5_59.0', 'x5_60.0', 'x5_61.0', 'x5_62.0', 'x5_63.0', 'x5_64.0', 'x5_65.0', 'x5_66.0', 'x5_67.0', 'x5_68.0', 'x5_69.0', 'x5_70.0', 'x5_71.0', 'x5_72.0', 'x5_73.0', 'x5_74.0', 'x5_75.0', 'x5_79.0', 'x6_-1.0', 'x6_-2.0', 'x6_0.0', 'x6_1.0', 'x6_2.0', 'x6_3.0', 'x6_4.0', 'x6_5.0', 'x6_6.0', 'x6_7.0', 'x6_8.0', 'x7_-1.0', 'x7_-2.0', 'x7_0.0', 'x7_1.0', 'x7_2.0', 'x7_3.0', 'x7_4.0', 'x7_5.0', 'x7_6.0', 'x7_7.0', 'x7_8.0', 'x8_-1.0', 'x8_-2.0', 'x8_0.0', 'x8_1.0', 'x8_2.0', 'x8_3.0', 'x8_4.0', 'x8_5.0', 'x8_6.0', 'x8_7.0', 'x8_8.0', 'x9_-1.0', 'x9_-2.0', 'x9_0.0', 'x9_1.0', 'x9_2.0', 'x9_3.0', 'x9_4.0', 'x9_5.0', 'x9_6.0', 'x9_7.0', 'x9_8.0']\n",
      "[34]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = train_ds.X_df.columns.tolist()\n",
    "print(cols)\n",
    "minority_inds = []\n",
    "for i in minority_indicators:\n",
    "    minority_inds.append(cols.index(i))\n",
    "print(minority_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ef5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "POISON_PROB = 0.0\n",
    "\n",
    "X_maj = []\n",
    "y_maj = []\n",
    "X_min = []\n",
    "y_min = []\n",
    "\n",
    "X_poison = []\n",
    "y_poison = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_poison.append(X_train[i])\n",
    "    if(X_train[i][minority_inds[0]] == 0.0):\n",
    "        X_maj.append(X_train[i])\n",
    "        if(y_train[i] == 0 and random.random() <= POISON_PROB):\n",
    "            y_maj.append(1) \n",
    "            y_poison.append(torch.Tensor([1]).int()[0])\n",
    "        else:\n",
    "            y_maj.append(y_train[i])\n",
    "            y_poison.append(y_train[i])\n",
    "    elif(X_train[i][minority_inds[0]] == 1.0):\n",
    "        X_min.append(X_train[i])\n",
    "        if(y_train[i] == 1 and random.random() <= POISON_PROB):\n",
    "            y_min.append(0) \n",
    "            y_poison.append(torch.Tensor([0]).int()[0])\n",
    "        else:\n",
    "            y_min.append(y_train[i])\n",
    "            y_poison.append(y_train[i])\n",
    "\n",
    "X_maj = np.asarray(X_maj)\n",
    "y_maj = np.asarray(y_maj)\n",
    "X_min = np.asarray(X_min)\n",
    "y_min = np.asarray(y_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f85c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "print(type(y_test[0]))\n",
    "print(torch.Tensor([0]).int()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a60cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class custDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X).float()\n",
    "        self.y = y\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "\n",
    "CustTrain = custDataset(X_poison, y_poison)    \n",
    "CustTest = custDataset(X_test, y_test)\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train, val, test, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_data = train\n",
    "        self.val_data = val\n",
    "        self.test_data = test\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "    \n",
    "dm = CustomDataModule(CustTrain, CustTest, CustTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff3aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18677 5323\n",
      "0.7782083333333333 0.22179166666666666\n",
      "3.5087356753710313 0.28500294479841515\n"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "o = 0\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i] == 0):\n",
    "        z += 1\n",
    "    elif(y_train[i] == 1):\n",
    "        o += 1 \n",
    "        \n",
    "zero_weight = z/o#len(y_train)\n",
    "one_weight = o/z #len(y_train)\n",
    "print(z, o)\n",
    "print(z/len(y_train), o/len(y_train))\n",
    "print(zero_weight, one_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacb38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.5           # Regularization Parameter (Weights the Reg. Term)\n",
    "EPSILON = 0.1          # Input Peturbation Budget at Training Time\n",
    "GAMMA = 0.0            # Model Peturbation Budget at Training Time \n",
    "                       #(Changed to proportional budget rather than absolute)\n",
    "    \n",
    "LEARN_RATE = 0.001     # Learning Rate Hyperparameter\n",
    "HIDDEN_DIM = 256       # Hidden Neurons Hyperparameter\n",
    "HIDDEN_LAY = 2         # Hidden Layers Hyperparameter\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "EPSILON_LINEAR = True   # Put Epsilon on a Linear Schedule?\n",
    "GAMMA_LINEAR = True     # Put Gamma on a Linear Schedule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79758f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET MODE TO:  GRAD\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mode = 'GRAD'\n",
    "model = XAIArchitectures.FullyConnected(hidden_dim=HIDDEN_DIM, hidden_lay=HIDDEN_LAY, dataset=dataset, mode=mode)\n",
    "model.set_params(alpha=ALPHA, epsilon=EPSILON, gamma=GAMMA, \n",
    "                learn_rate=LEARN_RATE, max_epochs=MAX_EPOCHS,\n",
    "                epsilon_linear=EPSILON_LINEAR, gamma_linear=GAMMA_LINEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5541da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | lays | ModuleList | 103 K \n",
      "1 | l1   | Linear     | 37.6 K\n",
      "2 | lf   | Linear     | 514   \n",
      "------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.416     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/matthewwicker/opt/anaconda3/envs/XAIenvironment/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d61f9cc2b141e8a1a5262dd7695167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(max_epochs=MAX_EPOCHS, accelerator=\"cpu\", devices=1)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "result = trainer.test(model, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"Poisoned\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "SCHEDULED = EPSILON_LINEAR or GAMMA_LINEAR\n",
    "MODEL_ID = \"%s_%s_FCN_e=%s_g=%s_a=%s_l=%s_h=%s_s=%s_p=%s\"%(dataset, mode, EPSILON, GAMMA, ALPHA, \n",
    "                                                        HIDDEN_LAY, HIDDEN_DIM, SCHEDULED, POISON_PROB)\n",
    "trainer.save_checkpoint(\"Poisoned/%s.ckpt\"%(MODEL_ID))\n",
    "torch.save(model.state_dict(), \"Poisoned/%s.pt\"%(MODEL_ID))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
